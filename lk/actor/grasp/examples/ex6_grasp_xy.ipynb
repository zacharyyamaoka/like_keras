{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok here is the gameplane!\n",
    "\n",
    "1. We will use this model: https://github.com/GouMinghao/rgb_matters/blob/main/rgbd_graspnet/net/fastpose.py\n",
    "2. Start with small resnet, un intialized weights\n",
    "3. make sure that loss decreases!\n",
    "4. need to change dimensions slightly to work for this case...\n",
    "5. To avoid doing that I can actually perhaps just scale up the env img?... actually smaller image better as less weights!\n",
    "\n",
    "Ok so the env should have the option to set side_size=10\n",
    "\n",
    "What will success look like? achieving low loss. but ultimatly we care about success rate.... moving average... \n",
    "\n",
    "Generate dataset.... full image for both image and label... Label is always a the tru case of the heatmap, which is 1 or 0 for where grasp would succeed or not.\n",
    "\n",
    "\n",
    "See design of dataset here: https://github.com/GouMinghao/rgb_matters/blob/main/rgbd_graspnet/data/graspnet.py\n",
    "\n",
    "Also CIFAR:\n",
    "\n",
    "https://docs.pytorch.org/vision/main/_modules/torchvision/datasets/cifar.html#CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Callable\n",
    "import gymnasium as gym\n",
    "import bam_gym \n",
    "from bam_gym import print_reset, print_step\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_size = 32\n",
    "max_radius = 3\n",
    "min_radius = 2\n",
    "num_circles = 1\n",
    "render_screen_scale = 10\n",
    "\n",
    "env = gym.make(\"bam_local/GraspXY\", render_mode=\"human\", screen_size=(screen_size, screen_size), max_radius=max_radius, min_radius=min_radius, num_circles=num_circles, render_screen_scale=render_screen_scale)\n",
    "print(\"Action Space:\", env.action_space)\n",
    "print(\"Observation Space:\", env.observation_space)\n",
    "state, info = env.reset()\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, info = env.reset()\n",
    "\n",
    "for i in range(10):\n",
    "    action = env.action_space.sample()\n",
    "    # action = policy(state)\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    # print_step(action, state, reward, terminated, truncated, info, i)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.unwrapped.get_binary_label()\n",
    "plt.imshow(env.unwrapped.get_binary_label(), cmap='gray', vmin=0, vmax=1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_data_pairs: list[tuple[np.ndarray, np.ndarray]] = env.unwrapped.create_dataset(100)\n",
    "\n",
    "plt.title(\"Histogram of image pixels\")\n",
    "plt.hist(env_data_pairs[0][0].flatten(), 255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_grid(image_label_list, nrows=4, ncols=8, figsize=(16, 8), cmap=None, show_labels=False):\n",
    "    \"\"\"Display a grid of images (optionally with labels) from a list of (image, label) tuples.\"\"\"\n",
    "    total = nrows * ncols\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for idx, (img, label) in enumerate(image_label_list[:total]):\n",
    "        ax = axes[idx]\n",
    "        if img.ndim == 2 or (img.ndim == 3 and img.shape[2] == 1):\n",
    "            ax.imshow(img.squeeze(), cmap=cmap or 'gray')\n",
    "        else:\n",
    "            ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        if show_labels:\n",
    "            ax.set_title(\"Label\")\n",
    "            if label is not None:\n",
    "                if label.ndim == 2:\n",
    "                    ax.imshow(label, cmap='jet', alpha=0.3)\n",
    "    for ax in axes[len(image_label_list[:total]):]:\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "show_image_grid(env_data_pairs, nrows=4, ncols=8, show_labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_size = 60000\n",
    "test_dataset_size = 10000\n",
    "\n",
    "\n",
    "\n",
    "def to_tensor_pairs(numpy_pairs: list[tuple[np.ndarray, np.ndarray]]):\n",
    "    tensor_pairs = []\n",
    "    for img, mask in numpy_pairs:\n",
    "        img_t = torch.from_numpy(img).permute(2,0,1).float() / 255.0\n",
    "        mask_t = torch.from_numpy(mask).unsqueeze(0).float()\n",
    "        tensor_pairs.append((img_t, mask_t))\n",
    "    return tensor_pairs\n",
    "\n",
    "train_data_pairs = to_tensor_pairs(env.unwrapped.create_dataset(train_dataset_size))\n",
    "\n",
    "test_data_pairs = to_tensor_pairs(env.unwrapped.create_dataset(test_dataset_size))\n",
    "\n",
    "\n",
    "print(\"Size of train tensor dataset:\", len(train_data_pairs))\n",
    "print(\"Shape of first image:\", train_data_pairs[0][0].shape)\n",
    "print(\"Shape of first mask:\", train_data_pairs[0][1].shape)\n",
    "\n",
    "print(\"Size of test tensor dataset:\", len(test_data_pairs))\n",
    "print(\"Shape of first image:\", test_data_pairs[0][0].shape)\n",
    "print(\"Shape of first mask:\", test_data_pairs[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.stack([img for img, _ in train_data_pairs], dim=0)\n",
    "\n",
    "# Compute per-channel mean and std across N,H,W\n",
    "mean = imgs.mean(dim=(0,2,3))   # [3]\n",
    "std  = imgs.std(dim=(0,2,3))    # [3]\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HeatmapDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_label_pairs: list[tuple[torch.Tensor, torch.Tensor]],\n",
    "        transform: Callable | None = None,\n",
    "        label_transforms: Callable | None = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        tensor_pairs: list of (img, mask) where\n",
    "            img: torch.Tensor [3,H,W], float in [0,1]\n",
    "            mask: torch.Tensor [1,H,W], float {0,1}\n",
    "        transform: applied to images\n",
    "        label_transforms: applied to masks\n",
    "        \"\"\"\n",
    "        self.data = input_label_pairs\n",
    "        self.transform = transform\n",
    "        self.label_transforms = label_transforms\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.label_transforms:\n",
    "            label = self.label_transforms(label)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.RandomCrop(32, padding=4),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std, inplace=True),\n",
    "])\n",
    "label_transforms = None\n",
    "# transforms.Compose([\n",
    "#     # transforms.ToTensor(),\n",
    "#     # transforms.Normalize(mean, std, inplace=True),\n",
    "# ])\n",
    "\n",
    "\n",
    "batch_size = 2**9\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "\n",
    "train_dataset = HeatmapDataset(train_data_pairs, transform=transform, label_transforms=label_transforms)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "test_dataset = HeatmapDataset(test_data_pairs, transform=transform, label_transforms=label_transforms)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(data_loader: DataLoader):\n",
    "    for images, labels in data_loader:\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))\n",
    "        break\n",
    "\n",
    "show_batch(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_batch_histograms(data_loader: torch.utils.data.DataLoader, n_batches: int = 1):\n",
    "    \"\"\"\n",
    "    Show histograms of pixel values from a few batches.\n",
    "    - Plots per-channel histograms for images\n",
    "    - Plots mask pixel distribution\n",
    "    \"\"\"\n",
    "    for batch_idx, (images, masks) in enumerate(data_loader):\n",
    "        # Flatten image values: [B, C, H, W] -> [Npixels_per_channel]\n",
    "        img_vals = images.permute(1,0,2,3).reshape(images.shape[1], -1)  # [C, N]\n",
    "        \n",
    "        # Flatten mask values: [B,1,H,W] -> [N]\n",
    "        mask_vals = masks.reshape(-1)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "        # --- Image histograms (per channel) ---\n",
    "        colors = ['r', 'g', 'b'] if images.shape[1] == 3 else ['k']\n",
    "        for c in range(images.shape[1]):\n",
    "            axes[0].hist(img_vals[c].numpy().ravel(), bins=50, color=colors[c], alpha=0.5, label=f\"Channel {c}\")\n",
    "        axes[0].set_title(\"Image Pixel Distribution\")\n",
    "        axes[0].legend()\n",
    "\n",
    "        # --- Mask histogram ---\n",
    "        axes[1].hist(mask_vals.numpy().ravel(), bins=50, color='gray', alpha=0.7)\n",
    "        axes[1].set_title(\"Mask Pixel Distribution\")\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        if batch_idx + 1 >= n_batches:\n",
    "            break\n",
    "show_batch_histograms(train_dataloader, n_batches=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bam_grasp.net.layers.Heatmap_Resnet import HeatmapResNet\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HeatmapResNet(num_layers=18, out_channels=1, output_downsample=4).to(device)\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(\n",
    "    model, \n",
    "    input_size=(batch_size, 3, 32, 32),  # Example input size for CIFAR images\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"params_percent\", \"kernel_size\", \"mult_adds\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=0.01)\n",
    "# scheduler = torch.optim.lr_scheduler.LinearLR(optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test one batch\n",
    "img, label = next(iter(train_dataloader))\n",
    "img, label = img.to(device), label.to(device)\n",
    "print(img.shape, label.shape)\n",
    "logits = model(img) \n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "epoch_total = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train() -> dict[str, float]:\n",
    "    model.train()\n",
    "    n_total = len(train_dataloader.dataset)\n",
    "    n_batches = len(train_dataloader)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X) \n",
    "        resized_pred = nn.functional.interpolate(pred, size=y.shape[-2:], mode=\"nearest\")\n",
    "\n",
    "        train_loss: torch.Tensor = loss_fn(resized_pred, y) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += train_loss.item()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = train_loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{n_total:>5d}]\")\n",
    "\n",
    "        if batch == 10:\n",
    "            break # slow down learning a bit so I can see the logs!\n",
    "\n",
    "    avg_loss = running_loss / n_batches\n",
    "    return {\"avg_loss\": avg_loss}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test() -> dict[str, float]:\n",
    "    n_total = len(test_dataloader.dataset)\n",
    "    n_batches = len(test_dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X: torch.Tensor = X.to(device)\n",
    "            y: torch.Tensor = y.to(device)\n",
    "            logits: torch.Tensor = model(X)\n",
    "\n",
    "            # accumulate loss\n",
    "            test_loss += loss_fn(logits, y).item()\n",
    "\n",
    "            # BUG: you cannot use this classificaiton style accuracy\n",
    "            # correct += (logits.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "            # --- accuracy ---\n",
    "            N, C, H, W = logits.shape\n",
    "            # flatten spatial+channel dims\n",
    "            logits_flat = logits.view(N, -1)   # (N, C*H*W)\n",
    "            y_flat = y.view(N, -1)             # (N, H*W) or (N, C*H*W) depending on encoding\n",
    "\n",
    "            # argmax per sample\n",
    "            pred_idx = logits_flat.argmax(dim=1)  # (N,)\n",
    "\n",
    "            hits = y_flat[torch.arange(N), pred_idx]          # (N,)\n",
    "            correct += (hits == 1).sum().item()\n",
    "            total += N\n",
    "\n",
    "\n",
    "    avg_loss = test_loss / n_batches\n",
    "    accuracy = correct / n_total\n",
    "    print(correct, n_total)\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    return {\"test_loss\": test_loss, \"test_accuracy\": accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    epoch_total += 1\n",
    "    print(f\"Epoch {epoch_total}\\n-------------------------------\")\n",
    "    train_info = train()\n",
    "    test_info = test()\n",
    "\n",
    "    train_losses.append(train_info[\"avg_loss\"])\n",
    "    test_losses.append(test_info[\"test_loss\"])\n",
    "    test_accuracies.append(test_info[\"test_accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(test_accuracies, label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_state(state: np.ndarray):\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        # transforms.RandomCrop(32, padding=4),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std, inplace=False),\n",
    "    ])\n",
    "\n",
    "    state_tensor = torch.from_numpy(state).permute(2,0,1).float() / 255.0 # Convert to tensor as above\n",
    "    state_tensor = transform(state_tensor) # Apply same transforms as test dataset\n",
    "    state_tensor = state_tensor.unsqueeze(0) # add batch dim\n",
    "    state_tensor = state_tensor.to(device) # move to same device as model\n",
    "\n",
    "    return state_tensor\n",
    "\n",
    "class HeatmapPolicy():\n",
    "    def __init__(self, model: nn.Module, preprocess_state: Callable, epsilon=0.2):\n",
    "\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.epsilon = epsilon\n",
    "        self.iter = 0\n",
    "        self.preprocess_state = preprocess_state\n",
    "        self.last_heatmaps = None\n",
    "\n",
    "\n",
    "    def __call__(self, state: np.ndarray):\n",
    "        self.iter += 1\n",
    "\n",
    "        state = self.preprocess_state(state)\n",
    "\n",
    "\n",
    "        heatmaps = self.model(state)\n",
    "        self.last_heatmaps = heatmaps\n",
    "        B, C, H, W = heatmaps.shape\n",
    "\n",
    "        if np.random.random() <= self.epsilon:\n",
    "            cs = torch.randint(C, (B,)) \n",
    "            xs = torch.randint(W, (B,))\n",
    "            ys = torch.randint(H, (B,))\n",
    "\n",
    "            coords = torch.stack([xs, ys, cs], dim=1)  # [B,3]\n",
    "            if C == 1:\n",
    "                coords = coords[:, :2]  # drop channel column -> [B,2]\n",
    "\n",
    "            if B == 1:\n",
    "                return tuple(int(v) for v in coords[0])\n",
    "            return coords\n",
    "\n",
    "        # Exploit: global argmax over (C,H,W) for each sample\n",
    "        heatmaps_flat = heatmaps.view(B, -1)                     # [B, C*H*W]\n",
    "        argmax_idx = heatmaps_flat.argmax(dim=1)               # [B]\n",
    "\n",
    "        # Decode to (c, y, x), then output as (c, x, y) (or (x,y) if C==1)\n",
    "        c = argmax_idx // (H * W)                     # [B]\n",
    "        rem = argmax_idx % (H * W)\n",
    "        y = rem // W\n",
    "        x = rem % W\n",
    "\n",
    "        if C == 1:\n",
    "            if B == 1:\n",
    "                return int(x.item()), int(y.item())\n",
    "            return torch.stack([x, y], dim=1)         # [B,2] -> (x,y)\n",
    "        else:\n",
    "            if B == 1:\n",
    "                return int(c.item()), int(x.item()), int(y.item())\n",
    "            return torch.stack([x, y, c], dim=1)      # [B,3] -> (c,x,y)\n",
    "\n",
    "print(preprocess_state(state).shape)\n",
    "\n",
    "policy = HeatmapPolicy(model, preprocess_state, epsilon=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, info = env.reset()\n",
    "action = policy(state)\n",
    "\n",
    "def display_heatmap(state, action, policy):\n",
    "\n",
    "\n",
    "    plt.title(\"state\")\n",
    "    plt.imshow(state)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.title(\"Heatmap\")\n",
    "    plt.imshow(policy.last_heatmaps[0,0,:,:].detach().cpu().numpy())\n",
    "    plt.colorbar()\n",
    "\n",
    "    x, y = action if isinstance(action, (tuple, list)) and len(action) == 2 else (action[1], action[2])\n",
    "    plt.scatter([x], [y], color='red', marker='x', s=100, label='Action')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "display_heatmap(state, action, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_history = []\n",
    "epsilon_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.unwrapped.render_mode = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, info = env.reset()\n",
    "\n",
    "policy.epsilon = 0.0\n",
    "\n",
    "for i in range(100):\n",
    "    # action = env.action_space.sample()\n",
    "    action = policy(state)\n",
    "    new_state, reward, terminated, truncated, info = env.step(action)\n",
    "    reward_history.append(reward)\n",
    "    epsilon_history.append(policy.epsilon)\n",
    "\n",
    "    if reward == 0:\n",
    "        display_heatmap(state, action, policy)\n",
    "    state = new_state\n",
    "\n",
    "    # print_step(action, state, reward, terminated, truncated, info, i)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(reward_history, label=\"Reward\")\n",
    "plt.plot(epsilon_history, label=\"Epsilon\", color='red')\n",
    "# Compute moving average\n",
    "window_size = 50\n",
    "if len(reward_history) >= window_size:\n",
    "    moving_avg = np.convolve(reward_history, np.ones(window_size)/window_size, mode='valid')\n",
    "    plt.plot(range(window_size-1, len(reward_history)), moving_avg, label=f\"Moving Avg ({window_size})\", color='orange')\n",
    "\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Reward History and Moving Average\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bam_ws_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
