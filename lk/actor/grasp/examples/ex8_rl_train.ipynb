{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to train using RL labels? where instead of densly annotated heat map labels we just have a couple (1-4) depending on arms actions per predcition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Callable\n",
    "import gymnasium as gym\n",
    "import bam_gym \n",
    "from bam_gym import print_reset, print_step\n",
    "import time\n",
    "np.random.seed(1)\n",
    "from bam_artist.heatmap_helper import show_heatmap_img, show_heatmap_img_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_size = 2**5\n",
    "render_screen_scale = 500/screen_size # Boost up pygame screen size if using small screen sizes\n",
    "print(\"Screen Size:\", screen_size)\n",
    "\n",
    "# Rectangul size is relative to screen size\n",
    "min_width = np.ceil(screen_size*0.01)\n",
    "max_width = min_width * 3\n",
    "print(\"Min Width:\", min_width)\n",
    "print(\"Max Width:\", max_width)\n",
    "N_ANGLES = 16       \n",
    "\n",
    "env = gym.make(\n",
    "    \"bam_local/GraspXYRZ\",\n",
    "    render_mode=\"human\",\n",
    "    screen_size=(screen_size, screen_size),\n",
    "    num_rectangles=5,\n",
    "    min_width=min_width,\n",
    "    max_width=max_width,\n",
    "    min_height_ratio=2,\n",
    "    max_height_ratio=5.0,\n",
    "    render_screen_scale=render_screen_scale,\n",
    "    n_angles=N_ANGLES\n",
    ")\n",
    "\n",
    "print(\"Action Space:\", env.action_space)\n",
    "print(\"Observation Space:\", env.observation_space)\n",
    "state, info = env.reset()\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_labels(state, label, alpha=0.5):\n",
    "    labels = []\n",
    "\n",
    "    for i in range(N_ANGLES):\n",
    "        angle = i*2*np.pi/N_ANGLES\n",
    "        # Wrap angle from pi to -pi, for easier understanding...\n",
    "        angle = (angle + np.pi) % (2 * np.pi) - np.pi\n",
    "        labels.append(f\"Angle {np.rad2deg(angle):.1f}° ~ {angle:.1f}rad\")\n",
    "\n",
    "    # When thinking about if the angle is correct, keep in mind the neutral positoin of the gripper... if at gripper 0, it should pick up an item along the x axis...\n",
    "    show_heatmap_img_grid(state, label, rows=2, cols=8, alpha=alpha, title_list=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, info = env.reset()\n",
    "env.unwrapped.render_mode = \"none\"\n",
    "for i in range(10):\n",
    "    action = env.action_space.sample()\n",
    "    print(action)\n",
    "    # action = policy(state)\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    view_labels(state, info[\"curr_label\"], alpha=0.9)\n",
    "    # time.sleep(0.5)\n",
    "    # print_step(action, state, reward, terminated, truncated, info, i)\n",
    "    break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_tensor_pairs(numpy_pairs: list[tuple[np.ndarray, np.ndarray]]) -> list[tuple[torch.Tensor, torch.Tensor]]:\n",
    "    # TODO this may be different depending on the incoming data...!\n",
    "    tensor_pairs = []\n",
    "    for img, mask in numpy_pairs:\n",
    "        img_t = torch.from_numpy(img).permute(2,0,1).float() / 255.0\n",
    "        mask_t = torch.from_numpy(mask).permute(2,0,1).float()\n",
    "        tensor_pairs.append((img_t, mask_t))\n",
    "    return tensor_pairs\n",
    "\n",
    "def plot_numpy_pairs(numpy_pairs: list[tuple[np.ndarray, np.ndarray]]):\n",
    "    # Plots just the images, not the labels!\n",
    "    images_to_plot = []\n",
    "    for i in range(64):\n",
    "        images_to_plot.append(numpy_pairs[i][0])\n",
    "\n",
    "    images_to_plot = torch.stack(images_to_plot)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    \n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(make_grid(images_to_plot[:64], nrow=8, pad_value=1).permute(1, 2, 0))\n",
    "\n",
    "def env_to_tensor_pairs(env, train_size, test_size, verbose=True, show=False):\n",
    "\n",
    "    assert hasattr(env.unwrapped, \"create_dataset\"), \"Environment must have a create_dataset method\"\n",
    "\n",
    "    dataset = env.unwrapped.create_dataset(1)\n",
    "    assert isinstance(dataset, list), \"Dataset must be a list of tuples\"\n",
    "    assert len(dataset) == 1, \"Dataset must have exactly one element\"\n",
    "    assert isinstance(dataset[0], tuple), \"Dataset must be a list of tuples\"\n",
    "    assert len(dataset[0]) == 2, \"Dataset must be a list of tuples\"\n",
    "    assert isinstance(dataset[0][0], np.ndarray), \"Dataset must be a list of tuples\"\n",
    "    assert isinstance(dataset[0][1], np.ndarray), \"Dataset must be a list of tuples\"\n",
    "    \n",
    "\n",
    "    train_data_pairs = numpy_to_tensor_pairs(env.unwrapped.create_dataset(train_size))\n",
    "\n",
    "    test_data_pairs = numpy_to_tensor_pairs(env.unwrapped.create_dataset(test_size))\n",
    "\n",
    "    if show:\n",
    "        plot_numpy_pairs(train_data_pairs)\n",
    "\n",
    "    if verbose:\n",
    "        # Verify the the C, H, W are in the correct order\n",
    "        print(\"Size of train tensor dataset:\", len(train_data_pairs))\n",
    "        print(\"Shape of first image:\", train_data_pairs[0][0].shape)\n",
    "        print(\"Shape of first mask:\", train_data_pairs[0][1].shape)\n",
    "\n",
    "        print(\"Size of test tensor dataset:\", len(test_data_pairs))\n",
    "        print(\"Shape of first image:\", test_data_pairs[0][0].shape)\n",
    "        print(\"Shape of first mask:\", test_data_pairs[0][1].shape)\n",
    "\n",
    "    return train_data_pairs, test_data_pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_scale = 10\n",
    "train_dataset_size = 6 * dataset_scale\n",
    "test_dataset_size = 1 * dataset_scale\n",
    "\n",
    "train_data_pairs, test_data_pairs = env_to_tensor_pairs(env, train_dataset_size, test_dataset_size, verbose=True, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bam_grasp.datasets.heatmap_dataset import HeatmapDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imgs = torch.stack([img for img, _ in train_data_pairs], dim=0)\n",
    "# Compute per-channel mean and std across N,H,W of (N,C,H,W)\n",
    "mean = imgs.mean(dim=(0,2,3))   # [3] for 3 channels\n",
    "std  = imgs.std(dim=(0,2,3))    # [3] for 3 channels\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean, std, inplace=True),\n",
    "])\n",
    "\n",
    "label_transforms = None\n",
    "\n",
    "\n",
    "batch_size = 2**9\n",
    "# batch_size = 2\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "\n",
    "\n",
    "train_dataset = HeatmapDataset(train_data_pairs, transform=transform, label_transforms=label_transforms)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "test_dataset = HeatmapDataset(test_data_pairs, transform=transform, label_transforms=label_transforms)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bam_utils.python.torch_helper import show_batch, show_batch_histograms\n",
    "\n",
    "show_batch(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch_histograms(train_dataloader, n_batches=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test one batch\n",
    "# img, label = next(iter(train_dataloader))\n",
    "# img, label = img.to(device), label.to(device)\n",
    "# print(img.shape, label.shape)\n",
    "# logits = model(img) \n",
    "\n",
    "# print(logits.shape)\n",
    "\n",
    "# assert logits.shape == label.shape\n",
    "\n",
    "# B, C, H, W = logits.shape\n",
    "# print(\"Total Action Space: \", C * H * W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Start a new wandb run to track this script.\n",
    "run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"zach-yamaoka-independent\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"bam-grasp\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    # job_type=\"test\",\n",
    "    group=\"compare_learning_rate_vs_actions_executed\",\n",
    "    config={\n",
    "        \"train_dataset_size\": train_dataset_size,\n",
    "        \"test_dataset_size\": test_dataset_size,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"n_executed_actions\": 8000, # lets do base 10 log, instead of base 2\n",
    "        \"mask_loss_fn\": True,\n",
    "    },\n",
    ")\n",
    "\n",
    "max_action = 32 * 32 * 16\n",
    "print(f\"Max action: {max_action}\")\n",
    "\n",
    "assert run.config[\"n_executed_actions\"] <= max_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bam_grasp.net.layers import HeatmapResNet, MaskedBCEWithLogitsLoss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HeatmapResNet(num_layers=18, out_channels=N_ANGLES).to(device)\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = summary(\n",
    "    model, \n",
    "    input_size=(batch_size, 3, 32, 32),  # Example input size for CIFAR images\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"params_percent\", \"kernel_size\", \"mult_adds\"]\n",
    ")\n",
    "print(info)\n",
    "torch.cuda.empty_cache()   # clears cached allocator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "masked_loss_fn = MaskedBCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=0.01)\n",
    "# scheduler = torch.optim.lr_scheduler.LinearLR(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "epoch_total = 0\n",
    "samples_total = 0\n",
    "wall_time_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader: DataLoader, n_executed_actions: int = 1, mask_loss_fn = False) -> dict[str, float]:\n",
    "    model.train()\n",
    "    n_total = len(data_loader.dataset)\n",
    "    n_batches = len(data_loader)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    K = n_executed_actions\n",
    "\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        logits = model(X) \n",
    "        # upsampled_logits = nn.functional.interpolate(logits, size=y.shape[-2:], mode=\"nearest\")\n",
    "\n",
    "\n",
    "\n",
    "        if mask_loss_fn: # this essential does epsilon = 1.0 random selection... may be suboptimal beacuse you keep on learning about the wrong actions... grr...\n",
    "\n",
    "            B, C, H, W = logits.shape\n",
    "\n",
    "            # Randomly select K actions to \"pretend\" to execute, we will read the results directly from the labels\n",
    "            c_executed = torch.randint(0, C, (B, K, 1), device=X.device)  # example: random ints in [0, 100)\n",
    "            h_executed = torch.randint(0, H, (B, K, 1), device=X.device)\n",
    "            w_executed = torch.randint(0, W, (B, K, 1), device=X.device)\n",
    "\n",
    "            executed_list = torch.cat([c_executed, h_executed, w_executed], dim=2)\n",
    "\n",
    "            assert executed_list.shape == (B, K, 3)\n",
    "\n",
    "            # Vectorized label gather from y: [B, C, H, W] -> [B, K]\n",
    "            b_idx = torch.arange(B, device=X.device)[:, None].expand(B, K)\n",
    "            # Do a matrix look up. All the indexs are of shape (B, K) and it returns a tensor of shape (B, K) at each index.\n",
    "            labels = y[\n",
    "                b_idx,\n",
    "                c_executed.squeeze(-1),\n",
    "                h_executed.squeeze(-1),\n",
    "                w_executed.squeeze(-1),\n",
    "            ]  # shape: [B, K]\n",
    "\n",
    "            executed_list_per_batch = list(executed_list.unbind(0))\n",
    "            labels_per_batch        = list(labels.unbind(0))\n",
    "            \n",
    "            train_loss: torch.Tensor = masked_loss_fn.forward(logits, executed_list_per_batch, labels_per_batch) \n",
    "        else:\n",
    "            train_loss: torch.Tensor = loss_fn.forward(logits, y) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += train_loss.item()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = train_loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{n_total:>5d}]\")\n",
    "\n",
    "    avg_loss = running_loss / n_batches\n",
    "    return {\"avg_loss\": avg_loss}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_loader: DataLoader) -> dict[str, float]:\n",
    "    n_total = len(data_loader.dataset)\n",
    "    n_batches = len(data_loader)\n",
    "    model.eval()\n",
    "    test_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            X: torch.Tensor = X.to(device)\n",
    "            y: torch.Tensor = y.to(device)\n",
    "            logits: torch.Tensor = model(X)\n",
    "\n",
    "            # accumulate loss\n",
    "            test_loss += loss_fn(logits, y).item()\n",
    "\n",
    "            # BUG: you cannot use this classificaiton style accuracy\n",
    "            # correct += (logits.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "            # --- accuracy ---\n",
    "            N, C, H, W = logits.shape\n",
    "            # flatten spatial+channel dims\n",
    "            logits_flat = logits.view(N, -1)   # (N, C*H*W)\n",
    "            y_flat = y.view(N, -1)             # (N, H*W) or (N, C*H*W) depending on encoding\n",
    "\n",
    "            # argmax per sample\n",
    "            pred_idx = logits_flat.argmax(dim=1)  # (N,)\n",
    "\n",
    "            hits = y_flat[torch.arange(N), pred_idx]          # (N,)\n",
    "            correct += (hits == 1).sum().item()\n",
    "            total += N\n",
    "\n",
    "\n",
    "    avg_loss = test_loss / n_batches\n",
    "    accuracy = correct / n_total\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    return {\"test_loss\": test_loss, \"test_accuracy\": accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_train_dataloader = train_dataloader\n",
    "_test_dataloader = test_dataloader\n",
    "\n",
    "if True:  # can I overfit to 100% a dataset? \n",
    "    _train_dataloader = test_dataloader\n",
    "    _test_dataloader = test_dataloader\n",
    "\n",
    "if run.config[\"mask_loss_fn\"]:\n",
    "    print(f\"Using masked loss fucntion for {run.config['n_executed_actions']} actions executed\")\n",
    "\n",
    "print(\"Using n_actions\")\n",
    "for epoch in range(1000):\n",
    "    epoch_total += 1\n",
    "    time_start = time.time()\n",
    "    print(f\"Epoch {epoch_total}\\n-------------------------------\")\n",
    "    train_info = train(_train_dataloader, run.config[\"n_executed_actions\"], run.config[\"mask_loss_fn\"])\n",
    "    test_info = test(_test_dataloader) \n",
    "\n",
    "    wall_time_total += time.time() - time_start\n",
    "    samples_total += len(_train_dataloader.dataset)\n",
    "\n",
    "    train_losses.append(train_info[\"avg_loss\"])\n",
    "    test_losses.append(test_info[\"test_loss\"])\n",
    "    test_accuracies.append(test_info[\"test_accuracy\"])\n",
    "\n",
    "    run.log({\n",
    "        \"train_loss\"     : train_info[\"avg_loss\"],\n",
    "        \"test_loss\"      : test_info[\"test_loss\"],\n",
    "        \"test_accuracy\"  : test_info[\"test_accuracy\"],\n",
    "        \"wall_time_total\": wall_time_total,\n",
    "        \"samples_total\"  : samples_total\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(test_accuracies, label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_state(state: np.ndarray):\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        # transforms.RandomCrop(32, padding=4),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std, inplace=False),\n",
    "    ])\n",
    "\n",
    "    state_tensor = torch.from_numpy(state).permute(2,0,1).float() / 255.0 # Convert to tensor as above\n",
    "    state_tensor = transform(state_tensor) # Apply same transforms as test dataset\n",
    "    state_tensor = state_tensor.unsqueeze(0) # add batch dim\n",
    "    state_tensor = state_tensor.to(device) # move to same device as model\n",
    "\n",
    "    return state_tensor\n",
    "\n",
    "class HeatmapPolicy():\n",
    "    def __init__(self, model: nn.Module, preprocess_state: Callable, epsilon=0.2):\n",
    "\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.epsilon = epsilon\n",
    "        self.iter = 0\n",
    "        self.preprocess_state = preprocess_state\n",
    "        self.last_heatmaps = None\n",
    "\n",
    "\n",
    "    def __call__(self, state: np.ndarray):\n",
    "        self.iter += 1\n",
    "\n",
    "        state = self.preprocess_state(state)\n",
    "\n",
    "\n",
    "        heatmaps = self.model(state)\n",
    "        # print(\"Logits shape:\", heatmaps.shape)\n",
    "        self.last_heatmaps = heatmaps\n",
    "        B, C, H, W = heatmaps.shape\n",
    "\n",
    "        if np.random.random() <= self.epsilon:\n",
    "            cs = torch.randint(C, (B,)) \n",
    "            xs = torch.randint(W, (B,))\n",
    "            ys = torch.randint(H, (B,))\n",
    "\n",
    "            coords = torch.stack([cs, xs, ys], dim=1)  # [B,3]\n",
    "            if C == 1:\n",
    "                coords = coords[:, 1:]  # drop channel column -> [B,2]\n",
    "\n",
    "            if B == 1:\n",
    "                return tuple(int(v) for v in coords[0])\n",
    "            return coords\n",
    "\n",
    "        # Exploit: global argmax over (C,H,W) for each sample\n",
    "        heatmaps_flat = heatmaps.view(B, -1)                     # [B, C*H*W]\n",
    "        argmax_idx = heatmaps_flat.argmax(dim=1)               # [B]\n",
    "\n",
    "        # Decode to (c, y, x), then output as (c, x, y) (or (x,y) if C==1)\n",
    "        c = argmax_idx // (H * W)                     # [B]\n",
    "        rem = argmax_idx % (H * W)\n",
    "        y = rem // W\n",
    "        x = rem % W\n",
    "\n",
    "        if C == 1:\n",
    "            if B == 1:\n",
    "                return int(x.item()), int(y.item())\n",
    "            return torch.stack([x, y], dim=1)         # [B,2] -> (x,y)\n",
    "        else:\n",
    "            if B == 1:\n",
    "                return int(c.item()), int(x.item()), int(y.item())\n",
    "            return torch.stack([c, x, y], dim=1)      # [B,3] -> (c,x,y)\n",
    "\n",
    "print(preprocess_state(state).shape)\n",
    "\n",
    "policy = HeatmapPolicy(model, preprocess_state, epsilon=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, info = env.reset()\n",
    "policy.epsilon = 0.0\n",
    "action = policy(state)\n",
    "print(action)\n",
    "\n",
    "# at zero deg the gripper should be point upwards! at 90, its 90deg offset..\n",
    "# Without the offset, then we are expecting the angle to be along the longital axis of the item\n",
    "gripper_offset = np.pi/2\n",
    "\n",
    "def display_heatmap(state, action, policy):\n",
    "    # Determine if action includes angle\n",
    "    if len(action) == 2:\n",
    "        x, y = action\n",
    "        angle = None\n",
    "    else:\n",
    "        c, x, y = action\n",
    "        angle = c * 2 * np.pi / N_ANGLES\n",
    "        angle *= -1 # make z go in other direction, I was expecting angle to start and x and go up, but... computer coordinates are strange...\n",
    "        # angle += gripper_offset\n",
    "        # angle = 0\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Plot state with action\n",
    "    axs[0].set_title(\"State\")\n",
    "    axs[0].imshow(state)\n",
    "    axs[0].scatter([x], [y], color='white', marker='x', s=100, label='Action')\n",
    "    if angle is not None:\n",
    "        dx = np.cos(angle) * max_width\n",
    "        dy = np.sin(angle) * max_width\n",
    "        axs[0].arrow(x, y, dx, dy, head_width=np.ceil(max_width*0.1), head_length=np.ceil(max_width*0.1), fc='white', ec='white')\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot heatmap with action\n",
    "    axs[1].set_title(\"Heatmap\")\n",
    "    heatmap = policy.last_heatmaps[0,:,:,:].detach().cpu().numpy()\n",
    "    # BUG: Arrow was appearing on a low score place... its beacuse you where just plotting the top angle...\n",
    "    heatmap = heatmap.max(axis=0) # show the max of any of the angles\n",
    "    im = axs[1].imshow(heatmap, cmap='hot')\n",
    "    axs[1].scatter([x], [y], color='blue', marker='x', s=100, label='Action')\n",
    "    if angle is not None:\n",
    "        dx = np.cos(angle) * max_width\n",
    "        dy = np.sin(angle) * max_width\n",
    "        axs[1].arrow(x, y, dx, dy, head_width=np.ceil(max_width*0.1), head_length=np.ceil(max_width*0.1), fc='blue', ec='blue')\n",
    "    axs[1].legend()\n",
    "    fig.colorbar(im, ax=axs[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "C, X, Y = action\n",
    "angle = C*2*np.pi/N_ANGLES\n",
    "angle = (angle + np.pi) % (2 * np.pi) - np.pi\n",
    "\n",
    "display_heatmap(state, action, policy)\n",
    "heatmap = policy.last_heatmaps[0,:,:,:].detach().cpu().numpy()\n",
    "heatmap = np.transpose(heatmap, (1, 2, 0))\n",
    "\n",
    "\n",
    "print(f\"Action Angle {np.rad2deg(angle):.1f}° or {angle:.1f}rad\")\n",
    "\n",
    "view_labels(state, heatmap, alpha=0.9)\n",
    "view_labels(state, info[\"curr_label\"], alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_history = []\n",
    "epsilon_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.unwrapped.render_mode = \"human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, info = env.reset()\n",
    "\n",
    "policy.epsilon = 0.0\n",
    "\n",
    "for i in range(10):\n",
    "    # action = env.action_space.sample()\n",
    "    action = policy(state)\n",
    "    new_state, reward, terminated, truncated, info = env.step(action)\n",
    "    reward_history.append(reward)\n",
    "    epsilon_history.append(policy.epsilon)\n",
    "\n",
    "    if reward == 0 and False:\n",
    "        C, X, Y = action\n",
    "        angle = C*2*np.pi/N_ANGLES\n",
    "        angle = (angle + np.pi) % (2 * np.pi) - np.pi\n",
    "\n",
    "        display_heatmap(state, action, policy)\n",
    "        heatmap = policy.last_heatmaps[0,:,:,:].detach().cpu().numpy()\n",
    "        heatmap = np.transpose(heatmap, (1, 2, 0))\n",
    "\n",
    "     \n",
    "        print(f\"Action Angle {np.rad2deg(angle):.1f}° or {angle:.1f}rad\")\n",
    "\n",
    "        view_labels(state, heatmap, alpha=0.9)\n",
    "        view_labels(state, info[\"last_label\"], alpha=0.9)\n",
    "\n",
    "        break\n",
    "    state = new_state\n",
    "\n",
    "    # print_step(action, state, reward, terminated, truncated, info, i)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(reward_history, label=\"Reward\")\n",
    "plt.plot(epsilon_history, label=\"Epsilon\", color='red')\n",
    "# Compute moving average\n",
    "window_size = 50\n",
    "if len(reward_history) >= window_size:\n",
    "    moving_avg = np.convolve(reward_history, np.ones(window_size)/window_size, mode='valid')\n",
    "    plt.plot(range(window_size-1, len(reward_history)), moving_avg, label=f\"Moving Avg ({window_size})\", color='orange')\n",
    "\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Reward History and Moving Average\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bam_ws_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
